# 1.15 流的Cookbook

## 1.15.1 介绍

这是一个, 用解决一些以`配方`形式展现的针对小目标的问题, 来展示`Akka Stream API`的多种多样的用法的模式的集合. 这页的意图在于给予一些如何用流来着手解决一些小任务的灵感和想法. 这页展示的配方可以直接拿来使用, 但是它们更多是作为一个起点: 极度鼓励去自定义一些代码片段. 

这个部分可以作为文档主体的一个补充材料. 当阅读手册时同时参看该页是一个很好的主意, 并且寻找各种在文档主体中出现的各种流概念的例子.

如果你需要这些配方中使用的可用处理步骤的快速引用, 可以参看`1.14 内置步骤概览和相关语义`.

## 1.15.2 用`Flow`来工作

在这个集合中我们展现一些包线性`Flow`的简单配方. 在本节中的配方是相当的基础, 更有针对性的配方在另一个独立的章节中(缓存和速率, 用流IO来工作).

### 记录一个流的元素

**情况**: 在开发过程中, 能够看到流的某一些特殊部分发生了什么，有时候非常有用.

最简单的解法是使用`map`操作和使用`println`来把接收到的元素打印到控制台. 由于这个配方非常简单, 它适用于快速debug的时候.

```scala

val loggedSource = mySource.map { elem => println(elem); elem }

```

另一个记录的方法是使用`log()`操作, 它允许配置记录在流中的元素, 同样包括完成和错误中的.

```scala

//自定义日志等级
mySource.log("before-map")
  .withAttributes(Attributes.logLevels(onElement = Logging.WarningLevel))
  .map(analyse)

//或者提供一个自定义的日志适配器
implicit val adapter = Logging(system, "customLogger")
mySource.log("custom")

```

### 序列流的扁平化

**情况**: 给定的一个流里包含的是序列元素, 但是需要一个包含基本元素的流, 分别把序列中嵌套的所有元素都流化. 

可以使用`mapConcat`操作来实现一对多的元素转化, 使用一个以`In => immutable.Seq[Out]`形式的函数作为一个映射函数. 在这个例子中我们希望使用能够映射一个`Seq`的元素到元素本身, 所以我们只要调用`mapConcat(identity)`.

```scala

val myData: Source[List[Message], Unit] = someDataSource

val flattened: Source[Message, Unit] = myData.mapConcat(identity)

```

### 流转化成严格集合

**情况**: 给定一个有限个数的元素序列流, 但是需要一个scala的集合.

在这个配方中, 我们将使用`grouped`流操作, 它将到来的元素组团成一个有限大小的集合的流(这个可以视为`序列流的扁平化`的反操作). 通过使用`grouped(MaxAllowedSeqSize)`我们创建了一个以`MaxAllowedSeqSize`为最大值的组的流, 然后我们通过加上`Sink.head`来获取这个流的第一个元素. 我们获取到的是一个包含了`MaxAllowedSeqSize`个数的原来流中元素序列的`Future`(其余更多的元素被丢弃了).

```scala

val strict: Future[immutable.Seq[Message]] =
  myData.grouped(MaxAllowedSeqSize).runWith(Sink.head)

```

### 计算一个ByteString流的摘要信息

**情况**: 给定一个字节流以`ByteString`流的形式, 我们想要计算出该流的加密摘要.

这个配方使用一个`PushPullStage`来持有一个可变的`MessageDigest`类(java Cryptography API的一部分), 然后随着字节流的到来更新它. 当流开始时, 该步骤的`OnPull`处理机被调用, 它只是把`Pull`事件冒泡给它的上游. 作为这个拉取的响应, 一个`ByteString`的块将到达(OnPush), 我们使用它来更新这个摘要, 然后该步骤将拉取下一个块.

最终这个`ByteString`将被耗尽并且我们将通过`onUpstreamFinish`收到该事件的消息通知. 当这个时候我们希望输出摘要值, 但是我们无法在这个处理者中直接实现. 相应的我们调用`ctx.absorbTermination()`来传递信号给上下文, 告知它我们并不想结束. 当环境决定我们可以输出更多元素时`onPull`再次被调用, 我们看到`ctx.isFinishing`返回了`true`(因为上游源已经被消耗光了). 由于我们只是希望输出一个最终的元素, 只需要调用`ctx.pushAndFinish`传递入想要输出的`ByteString`的摘要.

```scala

import akka.stream.stage._
def digestCalculator(algorithm: String) = new PushPullStage[ByteString, ByteString] {
  val digest = MessageDigest.getInstance(algorithm)

  override def onPush(chunk: ByteString, ctx: Context[ByteString]): SyncDirective = {
    digest.update(chunk.toArray)
    ctx.pull()
  }

  override def onPull(ctx: Context[ByteString]): SyncDirective = {
    if (ctx.isFinishing) ctx.pushAndFinish(ByteString(digest.digest()))
    else ctx.pull()
  }

  override def onUpstreamFinish(ctx: Context[ByteString]): TerminationDirective = {
    // 如果流完成了, 我们需要在onPull块中输出最后的元素
    // 无法在一个终止块中直接输出元素
    // (onUpstreamFinish 或者 onUpstreamFailure)
    ctx.absorbTermination()
    }
  }

val digest: Source[ByteString, Unit] = data.transform(() => digestCalculator("SHA-256"))  

```

### 从ByteString流中解析行

**情况**: 给定一个字节流以ByteString流的形式, 包含了需要解析的以行结束符为结尾的行(或者, 可选的, 包含以一个特殊分隔字节符分隔的二进制帧).

`Framing`帮助对象包含了一个便捷的方法来从`ByteStrings`中解析消息:

```scala

import akka.stream.io.Framing
val linesStream = rawData.via(Framing.delimiter(
  ByteString("\r\n"), maximumFrameLength = 100, allowTruncation = true))
  .map(_.utf8String)

```

### 实现 redcue-by-key

**情况**: 给定一个包含元素的流, 我们希望在元素的不同分组中计算一些聚合值.

reduce-by-key类型操作的`hello world`是`wordcount`, 我们将在下面展现. 给定一个包含词语的流, 我们首先创建一个依据`identity`函数创建出的分组的新流, 也就是说我们现在有了一个包含流的流, 每一个子流中包含相同的词语.

为了对词语计数, 我们需要处理这个包含流的流(实际上包含相同词语的分组). `groupBy`返回一个`SubFlow`, 意味着我们可以直接变换结果子流. 在这个例子中, 我们使用`fold`这个组合子来聚合词语本身和它出现的次数在一个二元组中(String, Integer). 每一个子流将输出一个最终值--准确的说是一个对--当所有的输入结束的完成时. 作为最后一步我们把从子流返回的值合并到一个单一的输出流. 

一个值得记录下的细节存在于`MaximumDistinctWords`参数: 它定义了groupBy和merge操作的适用性. `Akka Stream`关注在有边界的资源消耗并且打开的并发输入到merge操作的个数, 描述了merge本身需要的资源个数. 因此在任意给定时间内只有一个有限个数的子流是活跃的. 如果`groupBy`操作遇到了超过这个数字的key的个数, 那么流是无法在没有违法它边界资源的情况下继续下去, 在这种情况下`groupBy`将一个失败终结.

```scala

val counts: Source[(String, Int), Unit] = words
  // 首先把词语分割到不同的流中
  .groupBy(MaximumDistinctWords, identity)
  // 为这些流添加计数逻辑
  .fold(("", 0)) {
    case ((_, count), word) => (word, count + 1)
  }
  // 获取一个词语计数的流
  .mergeSubstreams

```

从这个`wordcount`中提取特殊的部分到

* 一个`groupKey`函数定义了如何进行分组
* 一个`foldZero`定义了作用在给定`group key`的子流上fold的初始元素
* 一个`fold`函数用来实施实际约简

我们得到了以下一个泛用版本:

```scala

def reduceByKey[In, K, Out](
  maximumGroupSize: Int,
  groupKey: (In) => K,
  foldZero: (K) => Out)(fold: (Out, In) => Out): Flow[In, (K, Out), Unit] = {

  Flow[In]
    .groupBy(maximumGroupSize, groupKey)
    .fold(Option.empty[(K, Out)]) {
      case (None, elem) =>
        val key = groupKey(elem)
        Some((key, fold(foldZero(key), elem)))
      case (Some((key, out)), elem) =>
        Some((key, fold(out, elem)))
    }
    .map(_.get)
    .mergeSubstreams
}

val wordCounts = words.via(reduceByKey(
  MaximumDistinctWords,
  groupKey = (word: String) => word,
  foldZero = (key: String) => 0)(fold = (count: Int, elem: String) => count + 1))

```

---

> **注意**: 请注意我们上面讨论的`reduce-by-key`版本是以串行的方式读取所有的输入, 也就是说它不是一个像`MapReduce`和其他相似框架的并行模式.

---


### 用groupBy将元素排序到多个组中

**情况**: `groupBy`操作严格的划分到来的元素, 每一个元素都仅属于一个分组. 有时候我们希望同时把元素映射到多个分组中.

为了获取想要的值, 我们把问题分成了两步:

* 首先, 使用一个`topicMapper`函数来提供一个消息隶属的话题(分组)列表, 我们变换`Message`流成为一个`(Message, Topic)`流, 在这里消息属于的每一个话题都将成为一个独立的对被输出. 这步由使用`mapConcat`来完成.

* 然后我们得到一个新的包含消息话题对元素的流(包含一个独立的对, 对于消息属于的每一个话题)并且传入到`groupBy`中, 把话题当成`group key`.

```scala

val topicMapper: (Message) => immutable.Seq[Topic] = extractTopics

val messageAndTopic: Source[(Message, Topic), Unit] = elems.mapConcat { msg: Message =>
  val topicsForMessage = topicMapper(msg)
  // Create a (Msg, Topic) pair for each of the topics
  // the message belongs to
  topicsForMessage.map(msg -> _)
}

val multiGroups = messageAndTopic
  .groupBy(2, _._2).map {
    case (msg, topic) =>
      // 做后续需要做的事
}


```

## 1.15.3 用`Graph`来工作

在这个集合中我们展示一些使用了`Graph`流元素来完成一些目标的配方. 

### 程序化触发Flow的元素

**情况**: 给定了一个流我们希望根据一个触发信号控制流元素的输出. 换句话说, 即使这个流可以流动(没有产生背压), 我们也希望控制住元素直到一个触发器信号到来.

这个配方用简单的zip了`Trigger`信号流和`Message`流来解决这个问题. 因为`Zip`生成两元对, 我们简单的映射输出流为选择两元对的第一个元素.

```scala

val graph = RunnableGraph.fromGraph(GraphDSL.create() { implicit builder =>
  import GraphDSL.Implicits._
  val zip = builder.add(Zip[Message, Trigger]())
  elements ~> zip.in0
  triggerSource ~> zip.in1
  zip.out ~> Flow[(Message, Trigger)].map { case (msg, trigger) => msg } ~> sink
  ClosedShape
})

```

另一种方案, 替换使用一个`Zip`, 然后使用`map`来获取二元对的第一个元素, 我们可以使用`ZipWith`来避免在第一步时创建一个二元对, 这个方法以一个接受两个参数的函数作为参数来创建输出元素. 如果
这个函数返回一个两个参数的二元对, 那么就和`Zip`的行为完全一致, 所以`ZipWith`是`Zip`的更泛用版本.

```scala

val graph = RunnableGraph.fromGraph(GraphDSL.create() { implicit builder =>
  import GraphDSL.Implicits._
  val zip = builder.add(ZipWith((msg: Message, trigger: Trigger) => msg))
  
  elements ~> zip.in0
  triggerSource ~> zip.in1
  zip.out ~> sink
  ClosedShape
})

```

### 平均分配任务到一个固定工作池

**情况**: 给定一个包含工作的流和一个用`Flow`描述的工人进程, 创建了一个工人池能够自动的平衡到来的工作到可用的工人上, 然后合并结果.

我们将把解法描述成一个函数, 该函数以一个工人流和分配的工人个数作为参数然后给定一个内部包含这些工人的一个池的`Flow`. 为了达成这个目标我们从一个`Graph`创建一个`Flow`.

这个`Graph`由一个`Balance`节点组成, 该节点是一个特殊的扇出操作, 它试图路由元素到可用的下游消费者. 在一个`For`循环中我们把所有的工人组装成输出给这个`balaner`的元素, 然后我们组装这些工人的输出到一个`Merge`元素, 它会从工人那搜集所有的结果.

```scala

def balancer[In, Out](worker: Flow[In, Out, Any], workerCount: Int): Flow[In, Out, Unit] = {
  import GraphDSL.Implicits._

  Flow.fromGraph(GraphDSL.create() { implicit b =>
    val balancer = b.add(Balance[In](workerCount, waitForAllDownstreams = true))
    val merge = b.add(Merge[Out](workerCount))

    for (_ <- 1 to workerCount) {
      // for each worker, add an edge from the balancer to the worker, then wire
      // it to the merge element
      balancer ~> worker ~> merge
    }

    FlowShape(balancer.in, merge.out)
  })
}

val processedJobs: Source[Result, Unit] = myJobs.via(balancer(worker, 3))

```
